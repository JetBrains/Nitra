using Nemerle;
using Nemerle.Collections;
using Nemerle.Text;
using Nemerle.Utility;
using Nemerle.Imperative;
using Nemerle.Extensions;

using Nitra.Runtime;
using Nitra.Runtime.Reflection;

using System;
using System.Diagnostics;
using System.IO;
using System.Linq;

using SCG = System.Collections.Generic;

namespace Nitra.Internal.Recovery
{
  public partial class RecoveryParser
  {
    internal RecordsToComplete : SCG.Queue[int * ParseRecord * ParsedSequence] = SCG.Queue();
    public Parse() : void
    {
      def completeAll() : void
      {
        while (RecordsToComplete.Count > 0)
        {
          def (endPos, caller, sequence) = RecordsToComplete.Dequeue();
          SubruleParsed(sequence.StartPos, endPos, caller, Records[caller.ParsePos][caller], sequence.Ends[endPos]);
        }
      }
      completeAll();
      while (RecordsToProcess.Count > 0)
      {
        when (IsRecordsToProcessCorrupted)
        {
          RecordsToProcess.RebuildHeap();
          IsRecordsToProcessCorrupted = false;
        }
        def (record, tokenChanges) = RecordsToProcess.ExtractFirst();
        when (!BestSolution.IsFail && tokenChanges > BestSolution)
        {
          RecordsToProcess.Insert(record, tokenChanges);
          return;
        }
        PredictionOrScanning(record, tokenChanges, optimize = !ErrorPositions.Contains(record.ParsePos));
        completeAll();
      }
    }

    public Completion(endPos : int, caller : ParseRecord, sequence : ParsedSequence) : void
    {
      RecordsToComplete.Enqueue(endPos, caller, sequence);
    }

    public PredictionOrScanning(record : ParseRecord, tokenChanges : TokenChanges, optimize : bool) : void
    {
      when (record.IsComplete)
      {
        when (record.ParsePos == ParseResult.Text.Length && StartSequence : object == record.Sequence)
          BestSolution = TokenChanges.Min(BestSolution, tokenChanges);
        record.Sequence.AddEnd(record.ParsePos, tokenChanges);
        return;
      }

      def state = record.ParsingState;
      when (state.CanConsumeErrorTokens)
      {
        def begin = record.ParsePos;
        mutable ends;
        when (Deleted.TryGetValue(begin, out ends))
          foreach (end in ends)
            SubruleParsed(begin, end, record, tokenChanges, TokenChanges(inserted = 0, deleted = 1));
      }

      def textPos = record.ParsePos;
      mutable endPos;
      //def skipRecord()
      //{
      //  when (record.Sequence.StartTokenChanges < tokenChanges)
      //  {
      //    def subruleTokenChanges = TokenChanges(inserted = record.ParsingState.MandatoryTokenCount, deleted = 0);
      //    SubruleParsed(textPos, textPos, record, tokenChanges, subruleTokenChanges);
      //  }
      //}
      match (state)
      {
        | Simple           as state =>
          if (optimize && { endPos = state.RuleParser.Parse(textPos, ParseResult.Text, ParseResult); endPos >= 0 &&
            {
              def p = ParseResult.ParseSession.CompletionStartPos;
              textPos >= p || endPos < p
            }})
          {
            SubruleParsed(textPos, endPos, record, tokenChanges, TokenChanges.None);
            when (textPos == endPos)
            {
              _ = StartParseSequence(record, textPos, state.RuleParser.ParsingSequence, tokenChanges);
              //skipRecord();
            }
          }
          else
          {
            _ = StartParseSequence(record, textPos, state.RuleParser.ParsingSequence, tokenChanges);
            //skipRecord();
          }

        | DynamicExtensibleItem as state =>
          def parser = state.RuleParser;
          ParseResult.ParseSession.CurrentGrammar = parser.Grammar;
          endPos = parser.Parse(textPos, ParseResult.Text, ParseResult);
          def grammarChanged = ParseResult.ParseSession.CurrentGrammar : object != parser.Grammar;
          when (grammarChanged)
          {
            SubruleParsed(textPos, endPos, record, tokenChanges, TokenChanges.None);
            def newParser = ParseResult.ParseSession.CurrentGrammar.GetExtensibleRuleParser(parser.Descriptor :> ExtensibleRuleDescriptor, "0");
            def newState = newParser.DynamicExtensibleParsingSequence.States[0];
            StartParseSubrule(ParseRecord(record.Sequence, newState.Id, endPos), tokenChanges);
          }

          if (optimize && { endPos >= 0 && 
            { 
              def p = ParseResult.ParseSession.CompletionStartPos;
              textPos >= p || endPos < p
            }})
          {
            SubruleParsed(textPos, endPos, record, tokenChanges, TokenChanges.None);
            when (textPos == endPos)
            {
              _ = StartParseSequence(record, textPos, parser.ParsingSequence, tokenChanges);
              //skipRecord();
            }
          }
          else
          {
            _ = StartParseSequence(record, textPos, parser.ParsingSequence, tokenChanges);
            //skipRecord();
          }

        | Extensible       as state =>
          if (optimize && { endPos = state.RuleParser.Parse(textPos, ParseResult.Text, ParseResult); endPos >= 0 && 
            { 
              def p = ParseResult.ParseSession.CompletionStartPos;
              textPos >= p || endPos < p
            }})
          {
            SubruleParsed(textPos, endPos, record, tokenChanges, TokenChanges.None);
            when (textPos == endPos)
            {
              _ = StartParseSequence(record, textPos, state.RuleParser.ParsingSequence, tokenChanges);
              //skipRecord();
            }
          }
          else
          {
            _ = StartParseSequence(record, textPos, state.RuleParser.ParsingSequence, tokenChanges);
            //skipRecord();
          }

        | ExtensionPrefix  as state =>
          foreach (prefixRule in state.RuleParser.PrefixRules)
            _ = StartParseSequence(record, textPos, prefixRule.ParsingSequence, tokenChanges);
          //skipRecord();

        | ExtensionPostfix as state =>
          foreach (postfixRule when state.RuleParser.FirstPostfixRuleId <= postfixRule.RuleId in state.RuleParser.PostfixRules)
            _ = StartParseSequence(record, textPos, postfixRule.ParsingSequence, tokenChanges);
          //skipRecord();

        | List(SubruleInfo = SubruleInfo.List as subrule) when subrule.IsOptimized =>
          endPos = subrule.Parse(textPos, ParseResult.Text, ParseResult);
          when (endPos >= textPos)
            SubruleParsed(textPos, endPos, record, tokenChanges, TokenChanges.None);

        | List              as state1 with seq = state1.Sequence
        | ListWithSeparator as state2 with seq = state2.Sequence
        | Subsequence       as state3 with seq = state3.Sequence
        | DynamicExtensible as state4 with seq = state4.Sequence =>
          _ = StartParseSequence(record, textPos, seq, tokenChanges);
          //skipRecord();

        | Scan             as state =>
          endPos = state.SubruleInfo.Parse(textPos, ParseResult.Text, ParseResult);
          when (endPos >= 0)
            SubruleParsed(textPos, endPos, record, tokenChanges, TokenChanges.None);
          //else
            //skipRecord();

        | Predicate        as state =>
          when (state.HeadPredicate(textPos, ParseResult.Text, ParseResult))
            SubruleParsed(textPos, textPos, record, tokenChanges, TokenChanges.None);
          //else
            //skipRecord();
      }
    }

    public StartParseSequence(startPos : int, parsingSequence : ParsingSequence, startTokenChanges : TokenChanges) : ParsedSequence
    {
      def key = (startPos, parsingSequence);
      mutable sequence;
      if (Sequences.TryGetValue(key, out sequence))
      {
        when (startTokenChanges < sequence.StartTokenChanges)
        {
          IsRecordsToProcessCorrupted = true;
          sequence.StartTokenChanges = startTokenChanges;
          sequence.StartParse();
          sequence.UpdateSubrules(sequence.StartPos);
        }
      }
      else
      {
        sequence = ParsedSequence(this, startPos, parsingSequence, startTokenChanges);
        Sequences.Add(key, sequence);
        sequence.StartParse();
      }
      sequence;
    }

    public StartParseSequence(caller : ParseRecord, startPos : int, parsingSequence : ParsingSequence, startTokenChanges : TokenChanges) : ParsedSequence
    {
      def sequence = StartParseSequence(startPos, parsingSequence, startTokenChanges);
      sequence.AddCaller(caller);
      sequence;
    }

    public StartParseSubrule(record : ParseRecord, tokenChanges : TokenChanges) : void
    {
      mutable set = Records[record.ParsePos];
      when (set == null)
      {
        set = Hashtable();
        Records[record.ParsePos] = set;
        MaxPos = Math.Max(MaxPos, record.ParsePos);
      }
      mutable oldTokenChanges;
      def newRecord =
        if (set.TryGetValue(record, out oldTokenChanges))
        {
          if (tokenChanges < oldTokenChanges)
          {
            set[record] = tokenChanges;
            true
          }
          else
            false
        }
        else
        {
          set.Add(record, tokenChanges);
          true
        };
      when (newRecord)
        RecordsToProcess.Insert(record, tokenChanges);
    }

    public SubruleParsed(begin : int, end : int, record : ParseRecord, tokenChanges : TokenChanges, subruleTokenChanges : TokenChanges) : void
    {
      unless (begin == end && record.ParsingState.IsNullable)
      {
        record.Sequence.AddParsedSubrule(ParsedSubrule(begin, end, record.State), subruleTokenChanges);
        foreach (next in record.ParsingState.Next)
          StartParseSubrule(record.Next(next, end), tokenChanges + subruleTokenChanges);
      }
    }
  }
}
