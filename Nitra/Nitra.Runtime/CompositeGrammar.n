using Nitra.Internal;
using Nitra.Internal.Recovery;
using Nitra.Runtime;
using Nitra.Runtime.Reflection;

using Nemerle;
using Nemerle.Collections;
using Nemerle.Text;
using Nemerle.Utility;

using System;
using System.Diagnostics;
using System.Linq;

using System.Xml.Linq;
using SCG = System.Collections.Generic;

namespace Nitra
{
#if !PARSER_DEBUG
  //[DebuggerStepThroughAttribute]
#endif
  public class CompositeGrammar
  {
    public Grammars                 : Set[GrammarDescriptor];
    public ParserHost               : ParserHost;
    public SimpleRuleParsers        : Hashtable[SimpleRuleDescriptor, SimpleRuleParser];
    public ExtensibleRules          : Hashtable[ExtensibleRuleDescriptor, ExtensibleRuleParserData] = Hashtable();
    public Tokens                   : SCG.Dictionary[object, TokenParser] = SCG.Dictionary();
    public VoidTokens               : SCG.Dictionary[object, TokenParser] = SCG.Dictionary();

    public StartID                  : int;
    public RuleParserMap            : SCG.List[object] = SCG.List();
    
    public Simples     : Seq[SimpleRuleParser];
    public Prefixs     : Seq[ExtensionRuleParser];
    public Postfixs    : Seq[ExtensionRuleParser];
    public Extensibles : Seq[ExtensibleRuleParser];

    public NewRuleId(ruleParser : object) : int
    {
      def id = StartID + RuleParserMap.Count;
      RuleParserMap.Add(ruleParser);
      id
    }

    internal this(parserHost : ParserHost)
    {
      StartID = 0;
      Grammars = Set();
      SimpleRuleParsers = Hashtable();
      ParserHost = parserHost;
    }

    internal this(parserHost : ParserHost, grammars : Set[GrammarDescriptor], startID : int)
    {
      StartID = startID;
      Grammars = grammars;
      ParserHost = parserHost;

      def rules = Grammars.SelectMany(gd => gd.Rules).NToArray();

      def extensionRuleDescriptors = rules
        .OfType.[ExtensionRuleDescriptor]()
        .Grouping(rd => (rd.BaseRule, rd))
        .Map((baseRd, extetions) =>
        {
          def prefix = extetions.OfType.[PrefixRuleDescriptor]().NToArray();
          def postfix = extetions.OfType.[PostfixRuleDescriptor]().NToArray();
          Array.Sort.[PostfixRuleDescriptor](postfix, ((l, r) => l.BindingPower.CompareTo(r.BindingPower)));
          (baseRd, (prefix, postfix))
        });

      foreach (extensibleRule in rules.OfType.[ExtensibleRuleDescriptor]())
      {
        def (prefixDescriptors, postfixDescriptors) = extensionRuleDescriptors.GetValueOrDefault(extensibleRule, (array[], array[]));
        ExtensibleRules[extensibleRule] = ExtensibleRuleParserData(this, extensibleRule, prefixDescriptors, postfixDescriptors);
      }

      SimpleRuleParsers = Hashtable(rules
        .OfType.[SimpleRuleDescriptor]()
        .Map(rd => (rd, rd.NewParser(this))));

      foreach (extensibleRule in ExtensibleRules)
        extensibleRule.Value.Init();

      foreach (kv in SimpleRuleParsers)
        kv.Value.Init();

      foreach (extensibleRule in ExtensibleRules)
        _ = GetExtensibleRuleParser(extensibleRule.Key, 0);

      InitTokens();

      Simples     = SimpleRuleParsers.Values.ToArray();
      def extensibleRules = ExtensibleRules.Values;
      Prefixs     = extensibleRules.Map(data => data.PrefixParsers).Flatten().ToArray();
      Postfixs    = extensibleRules.Map(data => data.PostfixParsers).Flatten().ToArray();
      Extensibles = extensibleRules.Map(data => data.Parsers.Filter(_ != null)).Flatten().ToArray();

      InitMandatoryTokenCount();
    }

    //public UpdateMandatoryTokens() : bool
    //{
    //  mutable min = ~int.MaxValue;
    //  foreach (ruleParser in PrefixRules)
    //  {
    //    def cur = ruleParser.MandatoryTokens;
    //    min = if (min < 0) if (cur < 0) if (~min < ~cur) min else cur
    //                       else         if (~min <  cur) min else cur
    //          else         if (cur < 0) if (min <= ~cur) min else cur
    //                       else         if (min <=  cur) min else cur
    //  }
    //  def updated = min != MandatoryTokens;
    //  MandatoryTokens = min;
    //  updated
    //}

    private InitMandatoryTokenCount() : void
    {
      def simple     = Simples     :> array[SimpleRuleParser];
      def prefix     = Prefixs     :> array[ExtensionRuleParser];
      def postfix    = Postfixs    :> array[ExtensionRuleParser];
      def extensible = Extensibles :> array[ExtensibleRuleParser];

      def addT(mt1 : int, mt2 : int) : int
      {
        if (mt1 < 0) if (mt2 < 0) ~(~mt1 + ~mt2)
                     else         ~(~mt1 +  mt2)
        else         if (mt2 < 0) ~( mt1 + ~mt2)
                     else          ( mt1 +  mt2)
      }

      def minT(mt1 : int, mt2 : int) : int
      {
        if (mt1 < 0) if (mt2 < 0) if (~mt1 < ~mt2) mt1 else mt2
                     else         if (~mt1 <  mt2) mt1 else mt2
        else         if (mt2 < 0) if (mt1 <= ~mt2) mt1 else mt2
                     else         if (mt1 <=  mt2) mt1 else mt2
      }

      def mulT(mt : int, times : int) : int
      {
        if (times == 0)
          0
        else if (mt < 0)
          ~((~mt) * times)
        else
          mt * times;
      }

      def initSequenceInfo(seq)
      {
        seq.MandatoryTokenCount = ~0;
        foreach (subrule in seq.Subrules)
        {
          subrule.MandatoryTokenCount = ~0;
          match (subrule)
          {
            | ListItem => assert(false)
            | Empty | RegularCall | TokenString | ExtensibleCall | SimpleCall => ()
            | Option            as subrule => initSequenceInfo(subrule.Rule);
            | List              as subrule => initSequenceInfo(subrule.Rule);
            | ListWithSeparator as subrule => initSequenceInfo(subrule.Rule); initSequenceInfo(subrule.Separator);
            | Marker                       => assert(false);
          }
        }
      }

      foreach (ruleParser in simple)     initSequenceInfo(ruleParser.SequenceInfo);
      foreach (ruleParser in prefix)     initSequenceInfo(ruleParser.SequenceInfo);
      foreach (ruleParser in postfix)    initSequenceInfo(ruleParser.SequenceInfo);
      foreach (ruleParser in extensible) ruleParser.MandatoryTokenCount = ~0;

      mutable updated = true;
      while (updated)
      {
        updated = false;
        def updateSequenceInfo(seq)
        {
          mutable count = 0;
          foreach (subrule in seq.Subrules)
          {
            subrule.MandatoryTokenCount = match (subrule)
            {
              | ListItem                     => assert(false);
              | Empty                        => 0;
              | RegularCall       as subrule => if (subrule.CanBeEmpty) 0 else 1;
              | TokenString       as subrule => if (subrule.Str == "") 0 else 1;
              | ExtensibleCall    as subrule =>
                if (subrule.RuleParser.Descriptor.IsTokenRule)
                  minT(subrule.RuleParser.MandatoryTokenCount, 1);
                else
                  subrule.RuleParser.MandatoryTokenCount

              | SimpleCall        as subrule =>
                if (subrule.RuleParser.Descriptor.IsTokenRule)
                  minT(subrule.RuleParser.SequenceInfo.MandatoryTokenCount, 1);
                else
                  subrule.RuleParser.SequenceInfo.MandatoryTokenCount

              | Option            as subrule =>
                updateSequenceInfo(subrule.Rule);
                0;

              | List              as subrule =>
                updateSequenceInfo(subrule.Rule);
                mulT(subrule.Rule.MandatoryTokenCount, subrule.Min);

              | ListWithSeparator as subrule =>
                updateSequenceInfo(subrule.Rule);
                updateSequenceInfo(subrule.Separator);
                match (subrule.Min)
                {
                  | 0 => 0
                  | 1 => subrule.Rule.MandatoryTokenCount
                  | c => addT(mulT(subrule.Rule.MandatoryTokenCount, c),  mulT(subrule.Separator.MandatoryTokenCount, (c - 1)))
                }

              | Marker                       => assert(false);
            }
            count = addT(count, subrule.MandatoryTokenCount);
          }
          updated = updated || count != seq.MandatoryTokenCount;
          seq.MandatoryTokenCount = count;
        }
        foreach (ruleParser in simple)     updateSequenceInfo(ruleParser.SequenceInfo);
        foreach (ruleParser in prefix)     updateSequenceInfo(ruleParser.SequenceInfo);
        foreach (ruleParser in postfix)    updateSequenceInfo(ruleParser.SequenceInfo);
        foreach (ruleParser in extensible)
        {
          mutable min = ~int.MaxValue;
          foreach (ruleParser in ruleParser.PrefixRules)
          {
            def cur = ruleParser.SequenceInfo.MandatoryTokenCount;
            min = minT(min, cur);
          }
          updated = updated || min != ruleParser.MandatoryTokenCount;
          ruleParser.MandatoryTokenCount = min;
        }
      }

      foreach (ruleParser in simple)     ruleParser.ParsingSequence = ParsingSequence.CreateSimple(ruleParser);
      foreach (ruleParser in prefix)     ruleParser.ParsingSequence = ParsingSequence.CreateExtension(ruleParser);
      foreach (ruleParser in postfix)    ruleParser.ParsingSequence = ParsingSequence.CreateExtension(ruleParser);
      foreach (ruleParser in extensible) ruleParser.ParsingSequence = ParsingSequence.CreateExtensible(ruleParser);

      def consumeErrorTokensToProcess = SCG.Stack();

      def updateTokens(parsingSequence : ParsingSequence)
      {
        when (parsingSequence.CanConsumeErrorTokens)
          consumeErrorTokensToProcess.Push(parsingSequence);

        def addToken(state, key : object)
        {
          mutable token;
          when (Tokens.TryGetValue(key, out token))
            _ = token.Callers.Add(ParsingCallerInfo(parsingSequence, state.Id))
        }
        foreach (state in parsingSequence.States)
        {
          | Predicate                  => ()
          | Simple            as state => _ = state.RuleParser.ParsingSequence.Callers.Add(ParsingCallerInfo(parsingSequence, state.Id)); when (state.RuleParser.IsTokenRule) addToken(state, state.RuleParser)
          | Extensible        as state => _ = state.RuleParser.ParsingSequence.Callers.Add(ParsingCallerInfo(parsingSequence, state.Id)); when (state.RuleParser.IsTokenRule) addToken(state, state.RuleParser)
          | List              as state1 with (seq = state1.Sequence, id = state1.Id)
          | ListWithSeparator as state2 with (seq = state2.Sequence, id = state2.Id)
          | Subsequence       as state3 with (seq = state3.Sequence, id = state3.Id) => _ = seq.Callers.Add(ParsingCallerInfo(parsingSequence, id)); updateTokens(seq);
          | Scan              as state =>
            match (state.Subrule)
            {
              | RegularCall as subrule => addToken(state, subrule.Descriptor)
              | TokenString as subrule => addToken(state, subrule.Str)
              | Empty                  => ()
              | _                      => assert3(false)
            }

          | ExtensionPrefix  as state =>
            foreach (parser in state.RuleParser.PrefixRules)
              _ = parser.ParsingSequence.Callers.Add(ParsingCallerInfo(parsingSequence, state.Id));

          | ExtensionPostfix as state =>
            foreach (parser when state.RuleParser.FirstPostfixRuleId <= parser.RuleId in state.RuleParser.PostfixRules)
              _ = parser.ParsingSequence.Callers.Add(ParsingCallerInfo(parsingSequence, state.Id));
        }
      }
      foreach (ruleParser in simple)     updateTokens(ruleParser.ParsingSequence);
      foreach (ruleParser in prefix)     updateTokens(ruleParser.ParsingSequence);
      foreach (ruleParser in postfix)    updateTokens(ruleParser.ParsingSequence);
      foreach (ruleParser in extensible) updateTokens(ruleParser.ParsingSequence);

      while (consumeErrorTokensToProcess.Count > 0)
        foreach ((parsingSequence, _) in consumeErrorTokensToProcess.Pop().Callers)
          unless (parsingSequence.CanConsumeErrorTokens)
          {
            parsingSequence.CanConsumeErrorTokens = true;
            consumeErrorTokensToProcess.Push(parsingSequence);
          }
    }

    private InitTokens() : void
    {
      def simpleVisited = SCG.HashSet();
      def extensibleVisited = SCG.HashSet();
      def visit(sequence)
      {
        foreach (subrule in sequence.Subrules)
        {
          | ListItem                     => assert(false);
          | Option            as subrule => visit(subrule.Rule);
          | List              as subrule => visit(subrule.Rule);
          | ListWithSeparator as subrule => visit(subrule.Rule);  visit(subrule.Separator);
          | ExtensibleCall    as subrule => visitExtensible(subrule.RuleParser);
          | SimpleCall        as subrule => visitSimple(subrule.RuleParser);
          | TokenString       as subrule => Tokens[subrule.Str]        = TokenParser.TokenString(subrule.Str);
          | Empty | Marker => ()
          | RegularCall       as subrule => 
            if (subrule.Descriptor.IsVoid)
              VoidTokens[subrule.Descriptor] = TokenParser.RegularCall(subrule.Descriptor);
            else
              Tokens[subrule.Descriptor]     = TokenParser.RegularCall(subrule.Descriptor);
        }
      }
      and visitSimple(parser)
      {
        if (parser.IsTokenRule)
        {
          if (parser.IsVoid)
            VoidTokens[parser] = TokenParser.SimpleCall(parser);
          else
            Tokens[parser]     = TokenParser.SimpleCall(parser);
        }
        else when (simpleVisited.Add(parser))
          visit(parser.Reflection(parser.RuleId));
      }
      and visitExtensible(parser)
      {
        if (parser.IsTokenRule)
        {
          if (parser.IsVoid)
            VoidTokens[parser] = TokenParser.ExtensibleCall(parser);
          else
            Tokens[parser]     = TokenParser.ExtensibleCall(parser);
        }
        else when (extensibleVisited.Add(parser))
        {
          foreach (parser in parser.PrefixRules)
            visit(parser.Reflection(parser.RuleId));
          for (mutable i = parser.FirstPostfixRule; i < parser.PostfixRules.Length; ++i)
          {
            def parser = parser.PostfixRules[i];
            visit(parser.Reflection(parser.RuleId));
          }
        }
      }

      foreach ((descriptor, parser) when descriptor.IsStartRule in SimpleRuleParsers.KeyValuePairs)
        visitSimple(parser);

      foreach ((descriptor, parserData) when descriptor.IsStartRule in ExtensibleRules.KeyValuePairs)
        visitExtensible(parserData.Parsers[0]);
    }

    public GetExtensibleRuleParser(rd : ExtensibleRuleDescriptor, bindingPower : int) : Internal.ExtensibleRuleParser
    {
      ExtensibleRules[rd].GetParser(bindingPower)
    }

    public GetSimpleRuleParser(rd : SimpleRuleDescriptor) : Internal.SimpleRuleParser
    {
      SimpleRuleParsers[rd]
    }
    
    public ParseAllNonVoidGrammarTokens(pos : int, parseResult : ParseResult) : SCG.HashSet[int]
    {
      def text = parseResult.Text;
      def results = SCG.HashSet.[int]();

      foreach (token in Tokens.Values)
        _ = results.Add(token.Parse(pos, text, parseResult));

      results
    }

    public ParseAllVoidGrammarTokens(pos : int, parseResult : ParseResult) : SCG.HashSet[int]
    {
      def text = parseResult.Text;
      def results = SCG.HashSet.[int]();

      foreach (token in VoidTokens.Values)
        _ = results.Add(token.Parse(pos, text, parseResult));

      results
    }
    
    public ParseAllGrammarTokens(pos : int, parseResult : ParseResult) : SCG.HashSet[int]
    {
      when (parseResult.TerminateParsing)
        throw OperationCanceledException();
        
      def text = parseResult.Text;
      def results = SCG.HashSet.[int]();

      foreach (token in Tokens.Values)
        _ = results.Add(token.Parse(pos, text, parseResult));

      foreach (token in VoidTokens.Values)
        _ = results.Add(token.Parse(pos, text, parseResult));

      when (parseResult.TerminateParsing)
        throw OperationCanceledException();
        
      results
    }

    public ParseNonVoidTokens(pos : int, parseResult : ParseResult) : SCG.List[TokenParserApplication]
    {
      when (parseResult.TerminateParsing)
        throw OperationCanceledException();
        
      def text = parseResult.Text;
      def results = SCG.List();

      foreach (token in Tokens.Values)
      {
        def newPos = token.Parse(pos, text, parseResult);
        when (newPos > pos)
          results.Add(TokenParserApplication(pos, newPos, false, token));
      }

      when (parseResult.TerminateParsing)
        throw OperationCanceledException();
        
      results
    }

    private static HtmlTemplate = @"
<html>
<head>
    <title>Pretty Print</title>
    <meta http-equiv='Content-Type' content='text/html;charset=utf-8'/>
    <style type='text/css'>
pre
{
  color: black;
  font-weight: normal;
  font-size: 12pt;
  font-family: Consolas, Courier New, Monospace;
}

.default
{
  color: black;
  background: white;
}

.keyword
{
  color: Blue;
}

.string
{
  color: Red;
}

.marker
{
  color: LightGray;
}

a:hover
{
  color: DarkBlue;
  font-weight: bold;
  text-decoration: none;
}


.simpleRuleCall
{
  color: DarkBlue;
}

.extensibleRuleCall
{
  color: DarkCyan;
}

.regexRuleCall
{
  color: DarkMagenta;
}

a:visited, a:link, a:active
{
  text-decoration: none;
}
</style>
</head>
<body>
<pre>
<content/>
</pre>
</body>
</html>
"; 
    
    public ToHtml() : XElement
    {
      def root       = XElement("span");
      def keywordCss = XAttribute("class", "keyword");
      def stringCss  = XAttribute("class", "string");
      def markerCss  = XAttribute("class", "marker");
      def seqInfoToLabelMap = Hashtable.[RuleDescriptor, string]();
      mutable id = 0;
      def getId()    : int    { id++; id }
      def getLabel(descriptor : RuleDescriptor) : string
      {
        mutable label;
        unless (seqInfoToLabelMap.TryGetValue(descriptor, out label))
        {
          label = "Ref_" + getId();
          seqInfoToLabelMap.Add(descriptor, label);
        }
        
        label
      }
      def renderAHref(descriptor : RuleDescriptor, text : string) : XElement
      {
        def cssClass =
          match (descriptor)
          {
            | SimpleRuleDescriptor     => "simpleRuleCall"
            | ExtensibleRuleDescriptor => "extensibleRuleCall"
            | RegularRuleDescriptor    => "regexRuleCall"
            | _                        => assert3(false);
          };
        
        XElement("a", XAttribute("href", "#" + getLabel(descriptor)), XAttribute("class", cssClass), text)
      }
      def convertSubrule(parent : XElement, subrule : SubruleInfo) : void
      {
        def predicates = subrule.HeadPredicates;
        
        foreach (predicate in predicates)
        {
          parent.Add(if (predicate.IsAnd) "&" else "!");
          renderSubSequence(parent, predicate, suppressParentheses=false);
          parent.Add(" ");
        }
        
        match (subrule)
        {
          | Empty                  => parent.Add(XElement("span", stringCss, <#""#>));
          | RegularCall       as r =>
            def descriptor = r.Descriptor;
            parent.Add(renderAHref(descriptor, descriptor.Name));
            
          | ExtensibleCall    as r =>
            def parser = r.RuleParser;
            def bp     = parser.BindingPower;
            parent.Add(renderAHref(parser.Descriptor, parser.Descriptor.Name));
            when (bp != 0)
              parent.Add(" : " + bp);
          
          | SimpleCall        as r =>
            def parser = r.RuleParser;
            parent.Add(renderAHref(parser.Descriptor, parser.Descriptor.Name));
          
          | Option            as r => renderSubSequence(parent, r.Rule, suppressParentheses=false); parent.Add("?");
          | ListItem          as _r => assert2(false); assert(false);
          | List              as r => renderSubSequence(parent, r.Rule, suppressParentheses=false); parent.Add(if (r.Min > 0) "+" else "*");
          | ListWithSeparator as r =>
            parent.Add("(");
            renderSubSequence(parent, r.Rule, suppressParentheses=true);
            parent.Add("; ");
            renderSubSequence(parent, r.Separator, suppressParentheses=true);
            when (r.HangingSeparator)
              parent.Add("; ?");
            parent.Add(if (r.Min > 0) ")+" else ")*");

          | TokenString       as r => parent.Add(XElement("span", stringCss, "\"" + X.EscapeString(r.Str) + "\""));
          | Marker            as r => parent.Add(XElement("span", markerCss, r.Name));
        }
      }
      and renderSubSequence(result : XElement, info : SequenceInfo, suppressParentheses : bool) : void
      {
        def needParentheses = !suppressParentheses && info.Subrules.Length != 1;
        when (needParentheses)
          result.Add("(");
        convertSubrules(result, info.Subrules);
        when (needParentheses)
          result.Add(")");
      }
      and convertSubrules(parent : XElement, subrules : array[SubruleInfo]) : void
      {
        foreach (subrule in subrules with i)
        {
          when (i != 0)
            parent.Add(" ");
          convertSubrule(parent, subrule);
        }
      }
      def getType(parser : RuleParser) : XElement
      {
        XElement("span", keywordCss, if (parser.IsVoid) "void " else if (parser.IsTokenRule) "token " else "syntax ")
      }
      def ruleHeader(prefix : XElement, parser : RuleParser, name : string, maxNameLen : int = 0) : XElement
      {
        def nameLen = name.Length;
        def title = XAttribute("title", "Syntax module: " + parser.Descriptor.Grammar.FullName 
          + ";  Assembly: " + parser.Descriptor.Grammar.GetType().Assembly.FullName);
        def result = XElement("span", XAttribute("id", getLabel(parser.Descriptor)), title);
        result.Add(prefix);
        result.Add(XElement("span", name));
        when (nameLen < maxNameLen)
          result.Add(string(' ', maxNameLen - nameLen));
        result
      }
      def renderPrefix(parser : ExtensionRuleParser, maxNameLen : int) : void
      {
        def (bp, baseRuleDescriptor) = if (parser.Descriptor is PostfixRuleDescriptor as postfix) (postfix.BindingPower, postfix.BaseRule) else (-1, null);
        def info   = parser.Reflection(parser.RuleId) :> SequenceInfo.Ast;
        def result = ruleHeader(XElement("span", "  | "), parser, parser.Descriptor.Name, maxNameLen);
        result.Add(" = ");
        when (bp >= 0)
        {
          def baseRule = this.ExtensibleRules[baseRuleDescriptor].GetParser(0);
          result.Add(XElement("span", " ", renderAHref(baseRule.Descriptor, baseRule.Descriptor.Name)));
          when (bp > 0)
            result.Add(" : " + bp + " ");
        }
        convertSubrules(result, info.Subrules);
        result.Add(";\r\n");
        root.Add(result);
      }

      def header = XElement("span");
      def assemblies = Grammars.GroupBy(g => g.GetType().Assembly);
      foreach (assembly in assemblies.OrderBy(a => a.Key.FullName))
      {
        header.Add(XElement("span", "Assemby: " + assembly.Key.FullName + "\r\n"));
        
        foreach (syntaxModule in assembly.OrderBy(m => m.FullName))
          header.Add(XElement("span", "  Syntax module: " + syntaxModule.FullName + "\r\n"));
      }
      
      header.Add(XElement("span", "\r\n"));
      
      root.Add(XElement("span", "\r\n"));
      
      def parsers = SCG.List.[StartRuleParser](Simples);
      parsers.AddRange(Extensibles.Where(e => e.BindingPower == 0));
      def parsers2 = parsers.OrderByDescending(_.IsTokenRule).ThenBy(x => x.Descriptor.Name);
      
      foreach (parser in parsers2)
      {
        | SimpleRuleParser as parser =>
          when (parser.Reflection(parser.RuleId) is SequenceInfo.Ast as info)
          {
            def result = ruleHeader(getType(parser), parser, parser.Descriptor.Name);
            result.Add(" = ");
            convertSubrules(result, info.Subrules);
            result.Add(";\r\n");
            root.Add(result);
          }
        
        | ExtensibleRuleParser as parser =>
          def result = ruleHeader(getType(parser), parser, parser.Descriptor.Name);
          root.Add(result);
          root.Add("\r\n{\r\n");
        
          def extensionRules = SCG.List(parser.PrefixRules.OrderBy(r => r.Descriptor.Name));
          extensionRules.AddRange(parser.PostfixRules.OrderBy(r => (r.Descriptor :> PostfixRuleDescriptor).BindingPower).ThenBy(r => r.Descriptor.Name));
          
          when (extensionRules.Count > 0)
          {
            def maxNameLen = extensionRules.Max(r => r.Descriptor.Name.Length);
            foreach(subParser in extensionRules)
              renderPrefix(subParser, maxNameLen);
          }
          
          root.Add("}\r\n");
          
        | _ => assert3(false);
      }

      foreach (descriptor is RegularRuleDescriptor in seqInfoToLabelMap.Keys.Distinct().OrderByDescending(_.Name))
        root.AddFirst(XElement("span", XAttribute("id", getLabel(descriptor)), XElement("span", keywordCss, "regex"), " ", descriptor.Name, " = ", descriptor.RegexText, ";\r\n"));
      
      root.AddFirst(header);
      
      def template = XElement.Parse(HtmlTemplate);
      def content = template.Descendants("content").First();
      Debug.Assert(content.Parent != null);
      content.Parent.ReplaceAll(root);
      template
    }
  }
}
